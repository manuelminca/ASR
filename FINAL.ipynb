{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fdH1KsKtnS8H",
    "outputId": "6bb0f21b-bef3-4781-a25c-ec9fba4949ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np  \n",
    "import h5py\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D,Conv1D, MaxPooling2D, Activation, LSTM, Reshape, Convolution2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "import sys\n",
    "from ipykernel import kernelapp as app\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "PcbOQYe6lTlS",
    "outputId": "8343c5d5-5c24-43cc-8410-8e68fa29d498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQT300secsallsongs.h5  LastModel.pt  cqt_main.py      manuenv\r\n",
      "FINAL.ipynb\t       MODEL.ipynb   finalDatasetCQT  mfcc_main.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-D0S2cR4nS-s"
   },
   "outputs": [],
   "source": [
    "#Loading all the necessary data of the dataset\n",
    "\n",
    "filename = \"CQT300secsallsongs.h5\"\n",
    "\n",
    "hf = h5py.File(filename, 'r') \n",
    "all_groups = list(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "JQHB75xOnTBe",
    "outputId": "bf29a58c-f3cb-4ada-ea3d-f7924e5e913e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(634960, 5, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/customopt/lamachine.stable/lib/python3.6/site-packages/ipykernel_launcher.py:13: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "fs = 44100      # samples/second\n",
    "#train_data = np.load(open('../musicnet.npz','rb'))\n",
    "#X,Y = train_data['2494'] # data X and labels Y for recording id 1788\n",
    "window_size = 384  # 2048-sample fourier windows\n",
    "wps = fs/float(512) # ~86 windows/second\n",
    "seconds = 20\n",
    "\n",
    "train_samples = 25\n",
    "#test_samples = 20\n",
    "\n",
    "#compute the number of windows\n",
    "\n",
    "with h5py.File(filename) as file:\n",
    "\n",
    "    size = 0\n",
    "    for i in range(train_samples):\n",
    "        iterations = file[all_groups[i]]['Labels'].shape[0]\n",
    "        size += iterations\n",
    "    \n",
    "    x_train = np.empty([int(size), 5, window_size]) #, dtype=np.complex)\n",
    "    y_train = np.empty([int(size),88])\n",
    "\n",
    "\n",
    "    #size = 0\n",
    "    #for i in range(test_samples):\n",
    "    #    iterations = file[all_groups[i + train_samples]]['Labels'].shape[0]\n",
    "    #    size += iterations\n",
    "    #    \n",
    "    #    \n",
    "    #x_test = np.empty([int(size), 5, window_size]) #, dtype=np.complex)\n",
    "    #y_test = np.empty([int(size),88])\n",
    "\n",
    "    \n",
    "print(x_train.shape)\n",
    "#print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/customopt/lamachine.stable/lib/python3.6/site-packages/ipykernel_launcher.py:2: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n",
      "100%|██████████| 318/318 [01:34<00:00,  3.35it/s]\n"
     ]
    }
   ],
   "source": [
    "maximo = 0\n",
    "with h5py.File(filename) as file:\n",
    "    for i in tqdm(range(len(all_groups))):\n",
    "        maximo = max(maximo, np.max(file[all_groups[i]]['CQT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.77573207375742"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "UcYSTzoqnTED",
    "outputId": "5a6ab8fd-07be-4ba9-c8af-1b099f04227f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/customopt/lamachine.stable/lib/python3.6/site-packages/ipykernel_launcher.py:2: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n",
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [10:24<00:00, 24.99s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "with h5py.File(filename) as file:\n",
    "    \n",
    "    print(\"Starting loading train samples\")\n",
    "    position = 0\n",
    "    for i in tqdm(range(train_samples)):\n",
    "        iterations = file[all_groups[i]]['Labels'].shape[0]\n",
    "        iterations = int(iterations)\n",
    "        for j in range(iterations):\n",
    "          if position < x_train.shape[0]:\n",
    "            \n",
    "            if j == 0:\n",
    "  \n",
    "              for k in range(5):\n",
    "                  if (j + k) < iterations:\n",
    "                      x_train[position][k] = file[all_groups[i]]['CQT'][j + k]\n",
    "              if j < (iterations - 2):\n",
    "                  y_train[position] = file[all_groups[i]]['Labels'][j + 2]\n",
    "              position = position + 1\n",
    "            else:\n",
    "              for k in range(5):\n",
    "                  if (j + k) < iterations:\n",
    "                      if k < 3:\n",
    "                        x_train[position][k] = x_train[position - 1][k + 1]\n",
    "                      else:\n",
    "                        x_train[position][k] = file[all_groups[i]]['CQT'][j + k]\n",
    "              if j < (iterations - 2):\n",
    "                  y_train[position] = file[all_groups[i]]['Labels'][j + 2]\n",
    "              position = position + 1\n",
    "              \n",
    "              \n",
    "              \n",
    "    #position = 0\n",
    "    #for i in range(test_samples):\n",
    "    #    print(i)\n",
    "    #    iterations = file[all_groups[i + train_samples]]['Labels'].shape[0]\n",
    "    #    iterations = int(iterations)\n",
    "    #    for j in range(iterations):\n",
    "    #      if position < x_test.shape[0]:\n",
    "    #        \n",
    "    #        if j == 0:\n",
    "  #\n",
    "    #          for k in range(5):\n",
    "    #              if (j + k) < iterations:\n",
    "    #                  x_test[position][k] = file[all_groups[i]]['CQT'][j + k]\n",
    "    #          if j < (iterations - 2):\n",
    "    #              y_test[position] = file[all_groups[i + train_samples]]['Labels'][j + 2]\n",
    "    #          position = position + 1\n",
    "    #        else:\n",
    "    #          for k in range(5):\n",
    "    #              if (j + k) < iterations:\n",
    "    #                  if k < 3:\n",
    "    #                    x_test[position][k] = x_test[position - 1][k + 1]\n",
    "    #                  else:\n",
    "    #                    x_test[position][k] = file[all_groups[i]]['CQT'][j + k]\n",
    "    #          if j < (iterations - 2):\n",
    "    #              y_test[position] = file[all_groups[i + train_samples]]['Labels'][j + 2]\n",
    "    #          position = position + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfdVltRxCAP6"
   },
   "outputs": [],
   "source": [
    "x_train == x_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "rhtvEEJUnTGs",
    "outputId": "f4c06f93-36c6-497b-86fe-3c55825aa2a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished convertion to Int\n",
      "Finished calculation of the maximum values\n",
      "0 24.05833589529093 24.05833589529093\n",
      "Finished reshaping\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype('int')\n",
    "#y_test = y_test.astype('int')\n",
    "print(\"Finished convertion to Int\")\n",
    "\n",
    "\n",
    "test_max = 41.77573207375742\n",
    "train_max = 41.77573207375742\n",
    "print(\"Finished calculation of the maximum values\")\n",
    "\n",
    "\n",
    "\n",
    "x_train /= max_value\n",
    "#x_test /= max_value\n",
    "\n",
    "\n",
    "data_rows, data_cols = 5, window_size\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], data_rows, data_cols, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], data_rows, data_cols, 1)\n",
    "print(\"Finished reshaping\")\n",
    "input_shape = (data_rows, data_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "En-YM1OxnTJd",
    "outputId": "e95f8bee-8a0a-4301-b6d7-5f898a8909b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258400, 5, 384, 1) x train shape\n",
      "(103360, 5, 384, 1) x test shape\n",
      "(258400, 88) y train shape\n",
      "(103360, 88) y test shape\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, 'x train shape')\n",
    "print(x_test.shape, 'x test shape')\n",
    "print(y_train.shape, 'y train shape')\n",
    "print(y_test.shape, 'y test shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwNHXO7avetL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 3, 374, 64)        2176      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 364, 64)        135232    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 182, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 182, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 11648)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1491072   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 88)                11352     \n",
      "=================================================================\n",
      "Total params: 1,639,832\n",
      "Trainable params: 1,639,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 507968 samples, validate on 126992 samples\n",
      "Epoch 1/10\n",
      "507968/507968 [==============================] - 685s 1ms/step - loss: 314687935.8892 - accuracy: 0.0186 - val_loss: 708459622.0355 - val_accuracy: 0.0198\n",
      "Epoch 2/10\n",
      "507968/507968 [==============================] - 686s 1ms/step - loss: 3621935356.6133 - accuracy: 0.0177 - val_loss: 4565924473.2105 - val_accuracy: 0.0013\n",
      "Epoch 3/10\n",
      "507968/507968 [==============================] - 690s 1ms/step - loss: 7369990713.3476 - accuracy: 0.0176 - val_loss: 7467748346.4523 - val_accuracy: 0.0013\n",
      "Epoch 4/10\n",
      "507968/507968 [==============================] - 696s 1ms/step - loss: 13069137856.0081 - accuracy: 0.0175 - val_loss: 12763905372.9883 - val_accuracy: 0.0308\n",
      "Epoch 5/10\n",
      "507968/507968 [==============================] - 697s 1ms/step - loss: 21117340559.3690 - accuracy: 0.0177 - val_loss: 18803523249.5905 - val_accuracy: 0.0313\n",
      "Epoch 6/10\n",
      "507968/507968 [==============================] - 697s 1ms/step - loss: 32286303801.6056 - accuracy: 0.0178 - val_loss: 27457162924.9459 - val_accuracy: 0.0096\n",
      "Epoch 7/10\n",
      "507968/507968 [==============================] - 694s 1ms/step - loss: 46512743380.5216 - accuracy: 0.0174 - val_loss: 39102273483.6195 - val_accuracy: 0.0051\n",
      "Epoch 8/10\n",
      "507968/507968 [==============================] - 698s 1ms/step - loss: 65116854388.8885 - accuracy: 0.0173 - val_loss: 49903981664.3750 - val_accuracy: 0.0075\n",
      "Epoch 9/10\n",
      "507968/507968 [==============================] - 696s 1ms/step - loss: 87678509496.7187 - accuracy: 0.0178 - val_loss: 63456909513.5230 - val_accuracy: 0.0051\n",
      "Epoch 10/10\n",
      "507968/507968 [==============================] - 708s 1ms/step - loss: 114661825613.5386 - accuracy: 0.0176 - val_loss: 77690225277.8551 - val_accuracy: 0.0198\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9e5f57717279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#score = model.evaluate(x_test, y_test, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 11),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 11), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(88, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=512,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)\n",
    "\n",
    "\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print(history.history.keys())  \n",
    "   \n",
    "plt.figure(1)  \n",
    "\n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/customopt/lamachine.stable/lib/python3.6/site-packages/ipykernel_launcher.py:6: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n",
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [09:03<00:00, 27.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 405236 samples, validate on 101310 samples\n",
      "Epoch 1/1\n",
      "405236/405236 [==============================] - 689s 2ms/step - loss: 173778673.2405 - accuracy: 0.0207 - val_loss: 732211845.2913 - val_accuracy: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [09:19<00:00, 27.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 412811 samples, validate on 103203 samples\n",
      "Epoch 1/1\n",
      "412811/412811 [==============================] - 695s 2ms/step - loss: 1955636459.5686 - accuracy: 0.0207 - val_loss: 958233238.2270 - val_accuracy: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [08:56<00:00, 26.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400036 samples, validate on 100009 samples\n",
      "Epoch 1/1\n",
      "400036/400036 [==============================] - 591s 1ms/step - loss: 1690269954.2872 - accuracy: 0.0216 - val_loss: 7009499255.6155 - val_accuracy: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [08:38<00:00, 25.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 396918 samples, validate on 99230 samples\n",
      "Epoch 1/1\n",
      "396918/396918 [==============================] - 599s 2ms/step - loss: 11106032014.8337 - accuracy: 0.0279 - val_loss: 5480270232.0108 - val_accuracy: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [08:57<00:00, 26.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 393920 samples, validate on 98481 samples\n",
      "Epoch 1/1\n",
      "393920/393920 [==============================] - 596s 2ms/step - loss: 32228958582.9953 - accuracy: 0.0181 - val_loss: 74474762429.1178 - val_accuracy: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [08:48<00:00, 26.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398659 samples, validate on 99665 samples\n",
      "Epoch 1/1\n",
      "398659/398659 [==============================] - 614s 2ms/step - loss: 118720942977.3598 - accuracy: 0.0180 - val_loss: 189593366987.5029 - val_accuracy: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:39<00:00, 16.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 263158 samples, validate on 65790 samples\n",
      "Epoch 1/1\n",
      "263158/263158 [==============================] - 398s 2ms/step - loss: 78666725402.9427 - accuracy: 0.0215 - val_loss: 3811838581.6223 - val_accuracy: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:52<00:00, 14.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 232388 samples, validate on 58097 samples\n",
      "Epoch 1/1\n",
      "197632/232388 [========================>.....] - ETA: 49s - loss: 5241408086.2176 - accuracy: 0.0377"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5a69e904977a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m               validation_split=0.2)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mcurrent\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/customopt/lamachine.stable/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/vol/customopt/lamachine.stable/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/customopt/lamachine.stable/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/customopt/lamachine.stable/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/customopt/lamachine.stable/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/customopt/lamachine.stable/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/customopt/lamachine.stable/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/vol/customopt/lamachine.stable/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_samples = 20\n",
    "current = 0\n",
    "\n",
    "with h5py.File(filename) as file:\n",
    "    \n",
    "    while current < (len(all_groups) -20 ):\n",
    "        \n",
    "        \n",
    "        size = 0\n",
    "        for i in range(train_samples):\n",
    "            iterations = file[all_groups[i + current]]['Labels'].shape[0]\n",
    "            size += iterations\n",
    "\n",
    "        x_train = np.empty([int(size), 5, window_size]) #, dtype=np.complex)\n",
    "        y_train = np.empty([int(size),88])\n",
    "\n",
    "\n",
    "        print(\"Starting loading train samples\")\n",
    "        position = 0\n",
    "        for i in tqdm(range(train_samples)):\n",
    "            iterations = file[all_groups[i + current]]['Labels'].shape[0]\n",
    "            iterations = int(iterations)\n",
    "            for j in range(iterations):\n",
    "              if position < x_train.shape[0]:\n",
    "\n",
    "                if j == 0:\n",
    "\n",
    "                  for k in range(5):\n",
    "                      if (j + k) < iterations:\n",
    "                          x_train[position][k] = file[all_groups[i+current]]['CQT'][j + k]\n",
    "                  if j < (iterations - 2):\n",
    "                      y_train[position] = file[all_groups[i+current]]['Labels'][j + 2]\n",
    "                  position = position + 1\n",
    "                else:\n",
    "                  for k in range(5):\n",
    "                      if (j + k) < iterations:\n",
    "                          if k < 3:\n",
    "                            x_train[position][k] = x_train[position - 1][k + 1]\n",
    "                          else:\n",
    "                            x_train[position][k] = file[all_groups[i+current]]['CQT'][j + k]\n",
    "                  if j < (iterations - 2):\n",
    "                      y_train[position] = file[all_groups[i+current]]['Labels'][j + 2]\n",
    "                  position = position + 1\n",
    "\n",
    "        x_train /= max_value\n",
    "        x_train = x_train.reshape(x_train.shape[0], data_rows, data_cols, 1)       \n",
    "\n",
    "        history = model.fit(x_train, y_train,\n",
    "              batch_size=512,\n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              validation_split=0.2)\n",
    "        \n",
    "        current += 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1054
    },
    "colab_type": "code",
    "id": "xE9jLEk8loiw",
    "outputId": "f371dd58-f270-4789-c500-6fc2cdd18499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 5, 384, 16)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 384, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5, 384, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 382, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3, 382, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3, 382, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 191, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 191, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 189, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 189, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 189, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 94, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 94, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 92, 32)         1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 92, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1, 92, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 46, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 46, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1472)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                94272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 88)                5720      \n",
      "=================================================================\n",
      "Total params: 107,192\n",
      "Trainable params: 106,904\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 258400 samples, validate on 103360 samples\n",
      "Epoch 1/20\n",
      " 12800/258400 [>.............................] - ETA: 1:30 - loss: 13.5544 - acc: 0.0144258400/258400 [==============================] - 57s 222us/step - loss: 12.5849 - acc: 0.0673 - val_loss: 11.8845 - val_acc: 0.0178\n",
      "Epoch 2/20\n",
      "129024/258400 [=============>................] - ETA: 23s - loss: 11.3347 - acc: 0.1143238592/258400 [==========================>...] - ETA: 3s - loss: 11.1034 - acc: 0.1148"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(5,5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32, (1, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(88, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.RMSprop(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=512,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "AmLlmgoF8vST",
    "outputId": "0270cc61-5772-4f9f-a159-d256b8ad1a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff5243b11d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAACfCAYAAADwMA5FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKMoApRKAoijKAKUSgKIoygD1/wE+z7hFHmU7UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff524382a90>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())  \n",
    "   \n",
    "plt.figure(1)  \n",
    "\n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8hMEewDPDuh"
   },
   "outputs": [],
   "source": [
    "with h5py.File(filename) as file:\n",
    "  print(file[all_groups[0]]['CQT'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lC94cMk2sFd"
   },
   "outputs": [],
   "source": [
    "x_test[51000]\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FINAL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
